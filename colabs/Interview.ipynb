{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UrologyUnbound/SIOP_ML_2024_Discord/blob/main/colabs/Interview.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating Interview Responses Notebook\n",
        "This notebook is designed to tackle the challenge of generating plausible responses to interview questions.  \n",
        "\n",
        "## Challenge Description\n",
        "Job candidates have responded to 5 common interview questions. We are given the text of 4 question and response pairs. Our task is to generate a likely text response for the 5th question based on the previous responses.  \n"
      ],
      "metadata": {
        "id": "0HTB8xVGCQCH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "np0Og4xLgs8u"
      },
      "outputs": [],
      "source": [
        "!pip install pandas langchain langchain_openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from langchain import FewShotPromptTemplate, PromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "C30NhuCOF__U"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interview_train_data = pd.read_csv(\"https://raw.githubusercontent.com/UrologyUnbound/SIOP_ML_2024_Discord/main/data/train/interview_train.csv\")\n",
        "interview_dev_data = pd.read_csv(\"https://raw.githubusercontent.com/UrologyUnbound/SIOP_ML_2024_Discord/main/data/dev/interview_val_public.csv\")"
      ],
      "metadata": {
        "id": "1HlUAssoGPEw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Manually add env key to the `api_key` argument\n",
        "llm = ChatOpenAI(api_key= userdata.get('OPENAI_API_KEY'), temperature=0.3)"
      ],
      "metadata": {
        "id": "73Mit7pHCOcB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "instructions = \"Your task is to analyze a dataset of interview questions and responses. Based on the content, tone, and details of the provided answers, your task is to generate a plausible answer for the fourth interview question.\""
      ],
      "metadata": {
        "id": "r_z3Pg-oCga6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_questions_answers(text):\n",
        "    # Split the text into parts based on \"Question:\" and \"Response:\" delimiters\n",
        "    parts = text.split(\"Question:\")[1:]\n",
        "    qas = []\n",
        "\n",
        "    last_question = \"\"\n",
        "\n",
        "    for part in parts:\n",
        "        q_a = part.split(\"Response:\")\n",
        "        question = q_a[0].strip()\n",
        "        answer = q_a[1].strip() if len(q_a) > 1 else \"\"\n",
        "        qas.append({\"question\": question, \"answer\": answer})\n",
        "        last_question = question\n",
        "\n",
        "    # return qas minus the last question, and the last question separately\n",
        "    return qas[:-1], last_question\n",
        "\n",
        "def create_examples(dataset_row):\n",
        "    # Extract questions and answers from each row of the dataset\n",
        "    # examples = extract_questions_answers(dataset_row)\n",
        "\n",
        "    examples, _ = extract_questions_answers(dataset_row)\n",
        "\n",
        "    return examples\n",
        "\n",
        "\n",
        "def create_example_prompt():\n",
        "    # Create a formatter for the examples\n",
        "    example_prompt = PromptTemplate(\n",
        "        input_variables=[\"question\", \"answer\"],\n",
        "        template=\"Question: {question}\\n{answer}\"\n",
        "    )\n",
        "\n",
        "    return example_prompt\n",
        "\n",
        "\n",
        "def create_template(dataset_row):\n",
        "    # Generate a few shot prompt template\n",
        "    examples, last_question = extract_questions_answers(dataset_row)\n",
        "\n",
        "    template = FewShotPromptTemplate(\n",
        "        # examples=create_examples(dataset_row),\n",
        "        examples=examples,\n",
        "        example_prompt=create_example_prompt(),\n",
        "        suffix=\"Question: {input}\",\n",
        "        input_variables=[\"input\"],\n",
        "    )\n",
        "\n",
        "    return template"
      ],
      "metadata": {
        "id": "lhj_wAR3b1Pa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create templates and fetch the last question for each row\n",
        "# prompt_templates = []\n",
        "formatted_prompts = []\n",
        "\n",
        "for i in range(len(interview_train_data)):\n",
        "    examples, last_question = extract_questions_answers(interview_train_data.loc[i, \"questions_answers\"])\n",
        "    prompt_template = create_template(interview_train_data.loc[i, \"questions_answers\"])\n",
        "    # prompt_templates.append(prompt_template)\n",
        "\n",
        "    formatted_prompt = prompt_template.format(input=last_question)\n",
        "    formatted_prompts.append(formatted_prompt)"
      ],
      "metadata": {
        "id": "Bhk-wY6ZcXx5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Output the response\n",
        "llm.invoke(formatted_prompts[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvJswmLRccfA",
        "outputId": "27376081-8df4-41df-f2b2-5f64e59e555a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='When motivating my team, I like to focus on setting clear goals and expectations, providing regular feedback and recognition, and fostering a positive and collaborative work environment. I believe in empowering team members to take ownership of their work and encouraging open communication.\\n\\nOne instance where this approach was particularly effective was when my team was working on a tight deadline for a project. I made sure to communicate the importance of the project, set clear milestones and deadlines, and provided support and resources to help them succeed. I also recognized and praised their hard work and dedication throughout the process. As a result, my team was motivated to work together efficiently and effectively to meet the deadline successfully.', response_metadata={'token_usage': {'completion_tokens': 131, 'prompt_tokens': 364, 'total_tokens': 495}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3bc1b5746c', 'finish_reason': 'stop', 'logprobs': None})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ]
}